Referee Report for
Mind Change Optimal Learning of Bayes Net Structure
from Dependency and Independency Data
by Oliver Schulte, Wei Luo and Russell Greiner

The paper submitted is interesting. It establishes the existence
of optimal learners with respect to mind change complexity and
convergence point; it furthermore gets a lower bound of the complexity
and shows that such learners are NP-hard under certain assumptions.
I recommend to accept the paper provided that the below changes
are made.

(1) Paper organization: It is recommended to split Section 6 into
two sections (according to the current subsections) and to integrate
the appendix into the corresponding section. Appendixes are normally
given at conference submissions where page limits do not permit to
have the full text in the conference version; but as this is now the
journal version, the organization of the paper should not longer
follow constraints stemming from the conference version.

[okay, need to interchange independence and dependence results]

(2) Upper bound: while a lower bound for the complexity of the learner
is given, an upper bound is missing. The authors should provide this
upper bound as well and discuss how much gap is left between lower and
upper bound of the learner's complexity.

(3) Normally, NP-hardness means that an NP-complete problem can be
polynomial-time many-one reduced or logspace many-one reduced to the
problem under consideration. Here, as the assumption P = RP indicates,
some other underlying reduction is used. It would be clearer, if the
assumption is not taken and instead, the corresponding reduction is
precisely spelled out - for example "randomized polynomial time Turing
reduction". Please determine the exact nature of the reduction and update
accordingly.

[explain reductions, added notation]

(4) The paper is well proof-read. Still, some few typing-errors remain.
Please unify the paper on whether two dots or three dots are used in
places like "1,...,m". One method to unify this would be to use the
latex-command "\ldots" for all type of dots which occur in the paper.

[done as suggested]

Furthermore, the references are not proofread well. "Information and
Computation" has different abbrevations at different places, reference
17 mentions the editor twice, words derived from proper names like
"Bayesian network", "problem of Mostowski" and "Ockham's razor" are
not capitalized the way they should be capitalized. So the authors
should go again over the whole paper before producing the final version
with a special attention to the references.

[done by Wei?]