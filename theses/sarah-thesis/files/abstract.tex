%% Copyright 1998 Pepe Kubon
%%
%% `abstract.tex' --- abstract for thes-full.tex, thes-short-tex from
%%                    the `csthesis' bundle
%%
%% You are allowed to distribute this file together with all files
%% mentioned in READ.ME.
%%
%% You are not allowed to modify its contents.
%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%       Abstract 
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\prefacesection{Abstract}
%Statistical Relational Learning is a new branch of machine learning that aims to model a joint distribution over relational data. Relational data consists of different types of objects where each object is characterized with a different set of attributes. The structure of relational data presents an opportunity for objects to carry additional information via their links and enables the model to show correlations among objects and their relationships. This dissertation focuses  on learning graphical models for such data.
%
%Learning graphical models for relational data is much more challenging than learning graphical models for propositional data. One of the challenges of learning graphical models for relational data is that relational data, unlike propositional data, is non independent and identically distributed and cannot be viewed in a single table. Relational data can be modeled using a graph, where objects are the nodes and relationships between the objects are the edges. In this graph, there may be multiple edges between two nodes because objects may have different types of relationships with each other. The existence of multiple paths of different length among objects makes the learning procedure much harder than learning from a single table. We use a lattice search approach with lifted learning to deal with the \emph{multiple path problem}.
%
%A key phenomenon that distinguishes relational data from single-population data is that the value of an attribute for an object can be predicted by the value of the same attribute for related objects, which are called recursive dependencies.  In terms of the relational graph described, recursive dependencies occur when an object of a specific type is connected to other objects of the same type. It is a challenge to define a closed-form likelihood function for directed graphical models for relational data in the presence of recursive dependencies. We utilize a recent pseudo likelihood that measures the fit of a directed graphical model to a relational database which is well-defined even in the presence of recursive dependencies.  We propose a new \emph{normal form theorem} that eliminates potential redundancies that arise when modelling recursive dependencies. We prove that under some mild constraints, the normal form involves no loss of expressive power.
%
%A well known problem with learning both on relational and propositional data is over-fitting where the learned model closely resembles only the training data and does not generalize. We propose parameter reduction methods augmenting decision trees with Bayesian networks for relational data to overcome over-fitting.   
%
%
%This dissertation focuses on learning the structure of Markov Logic Networks, which are a first order extension of Markov Random Fields. Markov Logic Networks are a prominent undirected statical relational model that have achieved impressive performance on a variety of statistical relational learning tasks. Our approach combines the scalability and efficiency of learning in directed relational models, and the inference power and theoretical foundations of undirected relational models. We utilize Parametrized Bayes nets, an extension of Bayesian networks based on first order logic,  for learning class-level or first-order dependencies, which model the general database statistics over attributes of linked objects and their links. 
%We then convert the Parametrized Bayes net to a Markov Logic Network using
%the standard moralization procedure.
%
%Experimental results indicate that our methods are two orders of magnitude faster than, and predictive metrics are superior or competitive with, state-of-the-art Markov Logic Network learners on six benchmark datasets.
        
        
Outliers are anomalous and interesting objects that are notably different from the rest of the data. Outliers often reveal useful information about the unusual behaviour of the systems and entities.  The identification of such abnormal behaviour provides valuable application-specific insights. 
Outlier Detection task has sometimes been considered as removing noise from
the data. However, it is usually the significantly interesting deviations that are
of most interest. There are many applications, such as detecting criminal activities and
identifying aircraft engine rotation defects, where finding outliers is crucial and
does not seem to be a straightforward task.


Different outlier detection techniques work with various data formats. For example, the data may be purely multidimensional or sequential with temporal
ordering or may be defined in the form of a network with arbitrary relationships
among data points. In addition, the attributes in the data may be numerical,
categorical or maybe mixed. The outlier detection process needs to be sensitive
to the nature of the underlying data.
Most of the previous work on outlier detection was designed for propositional data. This dissertation focuses on developing outlier detection methods for structured data, more specifically object-relational data. %Object-relational data is not independent and identically distributed and cannot be presented in a single table.
Object-relational data can be viewed as a heterogeneous network with different classes of objects and links.


We develop two new approaches to unsupervised outlier detection; both approaches leverage the statistical information obtained from a statistical-relational model. The first method develops a propositionalization approach to summarize information from object-relational data in a single data table.
We use Markove Logic Network (MLN) structure learning to construct the features for the single data table and to mitigate the loss of information that usually happens when features are generated by the manual aggregation.  By using propositionalization as a pipeline, we can apply many previous outlier detection methods that were designed for single-table data.
 
 %Our MLN-propositionalization approach summarizes the information from object-relational data that are typically stored in multiple tables, in a single data table without loss of information that usually happens when manually aggregate the features.
Our second outlier detection method ranks the objects as potential
outliers in an object-oriented data model. Our key idea is to compare the feature distribution of a potential outlier object with the feature distribution of the
objectâ€™s class. We introduce a novel distribution divergence
concept that is suitable for outlier detection. Our methods are validated on synthetic datasets and on real-world data
sets about soccer matches and movies.
%
%, specifically a Bayesian network. The first approach (propositionalization).
%
%In this dissertation, we first develop a novel propositionalization approach to unsupervised outlier detection for object-relational data. Propositionalization
%summarizes the information from object-relational data that are typically stored in multiple tables, in a single data table. By using propositionalization as a pipeline, we can apply many previous outlier detection methods that were design for single-table data.



















