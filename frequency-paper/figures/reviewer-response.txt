OBSOLETE---EDITED TEXT FOUND IN FILE "MLJ Revision Submitted Version.pdf"

Reply to the editor and reviewers:

We thank the reviewers and editors for their detailed rereading of our article. Their suggestions have improved the paper tremendously. This version of the paper has been extensively revised---every paragraph has been improved. Major changes include:

1. To improve the flow of expositions, we moved the detailed description of logic and semantics to Section 7, just before Related Work. In Section 2, we only introduce enough terms to describe the networks and algorithms.

2. Section 5, "Computing Relational Statistics", has been completely revised. We have added a new figure, showing the flow of the algorithm and emphasizing the distinction between Moebius parameters, joint probabilities, and conditional probabilities.

Reviewer #3 requested more details of the experiments. We made modest changes where we thought they improved clarity but did not add more detail. While we would like to have expanded the section, given space limitations and the aggregate concerns of all three reviewers, we concluded that the most important expansions in the paper should occur in the description of the algorithm. Given that the experimental methods replicate approaches and datasets used in papers that w cited, interested readers can readily obtain more detail. We believe that this is the best compromise.



OTHER THINGS?

Detailed responses to the reviewers:

Reviewer #1:

COMMENT: * Table 1 is incorrect in several ways, making the example rather confusing.

RESPONSE: [*Blush*] The table has been fixed. The LaTeX statements for the table are now automatically generated by the code that computes the table values.

COMMENT: (b)  The table seems to assume that Anna is a coffee drinker. However, according to the relational structure in Fig.1, there are no coffee drinkers (because there is no coffee drinker table). 

RESPONSE: CoffeeDrinker is the third column of the Person table. (No change to paper.)

COMMENT: (c)  You use {F,M} as the range for gender, while before it was {W,M}.

RESPONSE: We have tracked down every instance of "F" for "Female" and replaced it with "W".

COMMENT: * Difference with SRMs, p.17+18: I don't understand your point "(2)". Is this really a restriction of the SRM semantics, or of the inference method in SRMs? Is the point you raise here in some may related to the restriction of inference in SRMs mentioned on p.11, namely the restriction that the 1-minus trick can handle at most one negative relation? Or are these things unrelated? 

RESPONSE:  For the first question, it is a restriction of the SRM syntax, not the inference or the learning. This syntactic restriction reflects the SRM semantics. We changed our text to emphasize that the restriction is a matter of expressive power. For the second question, the 1-minus trick was presented as part of learning, not inference. And for PRMs, not SRMs. That said, it can probably be used for inference as well, and with SRMs as well. There is no explicit connection given in Getoor's work between SRMs and the 1-minus trick.

COMMENT: * p.9: You talk about "complete database" and "complete structure", where the former seems to be a subset of the latter. I'm not following here. What exactly is the "complete structure" ?

RESPONSE: We expanded this explanation at the beginning of Section 4. Hopefully it is clear now. In the i.i.d. setting, we can distinguish between a population and sample. In the relational setting, we distinguish between a complete network population structure and an observed substructure. This distinction helps us to discuss clearly issues around data completeness and the closed-world assumption as requested by the reviewers.

COMMENT: * Fig.4, caption of left part: You mention the "number of queries", e.g. 506 for Mondial, etc. What are these numbers? According to the text (p.14, line3) you use 100 test queries for all datasets?

RESPONSE: We expanded the description, thank you for drawing our attention to this.

COMMENT: * Fig.4, right part: Why are there no boxes/whiskers for the 70% and 90% on Financial? Also, what do the whiskers represent? As far as I know, it is common that the boxes in a box plot show 25% and 75% percentile, but I don't know of a common interpretation for the whiskers, so please specify.

[RESPONSE: There are no whiskers for the two entries in Financial because the variance is extremely small. We have added a note to Figure 4 to that effect. We have noted in the caption that the whiskers denote the 95th percentile.

RESPONSE: Explanation added (O.S.).

COMMENT: * p.8 (and rest of the paper) You say you refer to a PBN as simply a "Bayes net". I'm not a big fan of this terminology: a PBN and a regular BN are really different things, with e.g. a different semantics. I would prefer the acronym PBN instead of 'Bayes net'.

RESPONSE: Thank you for raising this issue. We can see how there may be potential for confusion about what semantics is intended. It's certainly the case that Poole's semantics for Parametrized Bayes nets is that they represent a single ground model. Our random selection semantics in contrast does not make reference to a single ground model, only to independent random groundings (see reply to reviewer #2). Another way to put this is that we use the *syntax* of Parametrized Bayes net, but not their semantics. To address this, we have adopted the approach of reference [13] (Schulte and Khosravi MLJ 2012): we use the term Functor Bayes net to denote a Bayes net with nodes that are built from functors and 1st-order/population variables, i.e. a Functor Bayes net has the same syntax as a Parametrized Bayes net. We then explain why we use a different term: because a Functor Bayes net does not (necessarily) have the same grounding semantics as a Parametrized Bayes net (nor does it require the specification of combining rules). This has the disadvantage of introducing a new term; but we agree with the reviewer that it's important to avoid misunderstandings about the semantics of the Bayes net models that we learn. 

COMMNT: Other comments (typos, details):

RESPONSE: Fixed.


Reviewer #2: 

COMMENT: It is not entirely correct to call this proposed method a non-ground semantics, it is really still a grounding semantics (hence you can reuse several "old" methods), but it is random grounding semantics. So, you still have to ground formulas to proceed with the method, but you ground a few, rather than all.

We rephrased to avoid the term "grounding-free" semantics. We added text to clarify the role of random groundings. The issue is a bit delicate because reviewer #3 raises the point that class-level inferences are *not* defined with respect to a ground model (e.g., the ground model of Figure 1 would have cycles). The fact of it is that our semantics uses (random) groundings but *not* a single ground model. We are aware that this is a subtle distinction, but it seems key to understanding how our work relates to previous work, and to responding to both reviewer comments. We edited the paper to make this distinction clear.

COMMENT: Conclusions, line 11: Mobious -> Mobius.

RESPONSE: Fixed.


Reviewer #3:

COMMENT: 1- The parameterized Bayes network is a DAG, but when grounded, it may no longer be a DAG (for instance when X=Y, there is a cycle on gender(X)). How is this taken into account?

RESPONSE: The random selection semantics is still well-defined even if the ground Bayes net contains cycles. This is basically because the semantics refers to (independent) random groundings, but not a single ground *model*. (Cf. response to reviewer #2). The same is true for the random selection pseudo-likelihood. The fact that these concepts are well-defined even in the presence of cyclic dependencies is one of their strengths. We have added comments to that effect, thank you for drawing our attention to this issue.

COMMENT: The paper is illustrated by a quite simple example: gender(X), gender(Y), friend(X,Y). What happens  with more complicated dependencies involving several relations? 

RESPONSE: The restriction to one relationship and two attributes was only for simplicity of illustration. The theory and algorithms are stated generally for an arbitrary number of relationships. Previous work has shown that structure learning scales well with both the size of the database and the number of relationships in it [see for instance the reference Schulte and Khosravi 2012]. We trust our extensive revision of Section 5 has clarified this.

[OS: should we add the number of relationships to the databases?]

COMMENT: 2- The second one concerns Mobius transformation: it is used only for boolean literals. Attribute literals are an extension of boolean literals and it could be used to compute the probability for the last value of the literal, given the (n-1) other ones. Does it mean that for the attribute literals the information must be complete? 

RESPONSE: The Mobius transform is performed one time for every possible combination of attribute values. We have added an explicit description of this in Section 5.2

COMMENT: 3- The structure of the Bayes network is learned by the learn-and-join algorithm. In fact, learning the structure of the model needs an evaluation of the model under construction. What is the underlying semantics used in the learn-and-join algorithm? Is it the same semantics as used in previous works or has it been adapted to this class-level semantics?

The objective function used in the learn-and-join algorithm is also the random selection pseudo likelihood (see the Schulte2011 SDM paper, also the Schulte & Khosravi AAAI and MLJ papers). The way instance-level inferences are done in those papers is by converting the Parametrized Bayes Net to a Markov Logic Network (using moralization), then applying Markov Logic Network inference. We expanded the discussion of instance-level inferences a bit to provide at least the relevant inferences.

COMMENT: 4- In the experiments, the structure of the database should be given.

RESPONSE: Due to space limitations, we chose not to give the structure. We cite a paper in which the details are given, as well as the direct sources of the databases. Interested readers can locate full descriptions of the database with only a little work.

COMMENT: 5- In the experiments what are the lengthes of the query? They seem quite short. How many relations are involved?

RESPONSE: 2-5 variables involved (random selection). The number of relations depends on the number on the database, we randomly select nodes from the Bayes net, including relationship nodes. We have expanded the description of the query generation procedure.

COMMENT: I do think that an important parameter, which is not taken into account is the number of relations  in the databases and in the queries. 

RESPONSE: We added the number of relations to the descriptions of the databases. The number of relations in the queries depends on those in the database. 

COMMENT: The experiment section must be developed for publication in Machine Learning

RESPONSE: See comments at beginning of this response.
